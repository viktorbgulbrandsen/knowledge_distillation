{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6a8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: c:\\Users\\vikto\\Desktop\\mat-stk2011\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"experiments\":\n",
    "    os.chdir(cwd.parent)\n",
    "print(\"Working dir:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2d688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from src.utils.seeds import seed_everything\n",
    "from src.utils.metrics import quadratic_weighted_kappa\n",
    "from src.utils.splits import get_stratified_folds\n",
    "\n",
    "seed_everything(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d304c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: (17307, 84)\n"
     ]
    }
   ],
   "source": [
    "spacy = np.load(\"data/cached_features_spacy.npz\")\n",
    "X = spacy[\"X\"]\n",
    "\n",
    "teacher = np.load(\"outputs/2026-02-20_16-53_teacher_cv/oof_predictions.npz\")\n",
    "y_true = teacher[\"y\"].astype(int)\n",
    "soft_probs = teacher[\"probs\"]\n",
    "soft_targets = soft_probs @ np.arange(1, soft_probs.shape[1] + 1)\n",
    "\n",
    "folds = get_stratified_folds(y_true, n_splits=5, seed=42)\n",
    "n = len(y_true)\n",
    "\n",
    "print(\"Features:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c97a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def evaluate_model(model_fn, X, targets, y_true, folds, regression=True):\n",
    "    oof = np.zeros(n)\n",
    "\n",
    "    total_leaves = 0\n",
    "\n",
    "    for tr_idx, va_idx in folds:\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(X[tr_idx])\n",
    "        X_va = scaler.transform(X[va_idx])\n",
    "\n",
    "        model = model_fn()\n",
    "        model.fit(X_tr, targets[tr_idx])\n",
    "\n",
    "        raw = model.predict(X_va)\n",
    "        if regression:\n",
    "            oof[va_idx] = np.clip(np.round(raw), 1, 6)\n",
    "        else:\n",
    "            oof[va_idx] = raw\n",
    "\n",
    "        # count leaves\n",
    "        if hasattr(model, \"tree_\"):\n",
    "            total_leaves += model.tree_.n_leaves\n",
    "        elif hasattr(model, \"estimators_\"):\n",
    "            for est in np.array(model.estimators_).flat:\n",
    "                total_leaves += est.tree_.n_leaves\n",
    "\n",
    "    qwk = quadratic_weighted_kappa(y_true, oof.astype(int))\n",
    "    avg_leaves = total_leaves / len(folds)\n",
    "\n",
    "    return qwk, avg_leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20178d9d",
   "metadata": {},
   "source": [
    "# Depth sweep over trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ea37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth=   2  hard=0.5756 (4 leaves)  soft=0.5710 (4 leaves)\n",
      "depth=   3  hard=0.6310 (8 leaves)  soft=0.6546 (8 leaves)\n",
      "depth=   4  hard=0.6527 (16 leaves)  soft=0.6646 (16 leaves)\n",
      "depth=   5  hard=0.6635 (32 leaves)  soft=0.6675 (32 leaves)\n",
      "depth=   6  hard=0.6650 (63 leaves)  soft=0.6823 (61 leaves)\n",
      "depth=   8  hard=0.6678 (189 leaves)  soft=0.6823 (175 leaves)\n",
      "depth=  10  hard=0.6547 (392 leaves)  soft=0.6872 (372 leaves)\n",
      "depth=  12  hard=0.6440 (615 leaves)  soft=0.6837 (623 leaves)\n",
      "depth=  15  hard=0.6339 (833 leaves)  soft=0.6769 (934 leaves)\n",
      "depth=  20  hard=0.6304 (946 leaves)  soft=0.6740 (1077 leaves)\n",
      "depth=None  hard=0.6305 (953 leaves)  soft=0.6741 (1082 leaves)\n"
     ]
    }
   ],
   "source": [
    "depths = [2, 3, 4, 5, 6, 8, 10, 12, 15, 20, None]\n",
    "\n",
    "dt_hard = []\n",
    "dt_soft = []\n",
    "\n",
    "for d in depths:\n",
    "    label = str(d) if d else \"None\"\n",
    "\n",
    "    fn_hard = lambda d=d: DecisionTreeClassifier(max_depth=d, min_samples_leaf=10)\n",
    "    qwk_h, leaves_h = evaluate_model(fn_hard, X, y_true, y_true, folds, regression=False)\n",
    "    dt_hard.append({\"depth\": label, \"qwk\": qwk_h, \"leaves\": leaves_h})\n",
    "\n",
    "    fn_soft = lambda d=d: DecisionTreeRegressor(max_depth=d, min_samples_leaf=10)\n",
    "    qwk_s, leaves_s = evaluate_model(fn_soft, X, soft_targets, y_true, folds)\n",
    "    dt_soft.append({\"depth\": label, \"qwk\": qwk_s, \"leaves\": leaves_s})\n",
    "\n",
    "    print(f\"depth={label:>4s}  hard={qwk_h:.4f} ({leaves_h:.0f} leaves)  soft={qwk_s:.4f} ({leaves_s:.0f} leaves)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418616c1",
   "metadata": {},
   "source": [
    "# Random Forest - n_estimators sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65901ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF n=  5  hard=0.6888 (757 leaves)  soft=0.6988 (776 leaves)\n",
      "RF n= 10  hard=0.6981 (1505 leaves)  soft=0.7012 (1557 leaves)\n",
      "RF n= 20  hard=0.6978 (2996 leaves)  soft=0.7020 (3124 leaves)\n",
      "RF n= 50  hard=0.7001 (7457 leaves)  soft=0.7013 (7772 leaves)\n",
      "RF n=100  hard=0.6998 (14951 leaves)  soft=0.7035 (15512 leaves)\n",
      "RF n=200  hard=0.7013 (29964 leaves)  soft=0.7043 (30975 leaves)\n"
     ]
    }
   ],
   "source": [
    "n_trees_list = [5, 10, 20, 50, 100, 200]\n",
    "\n",
    "rf_hard = []\n",
    "rf_soft = []\n",
    "\n",
    "for nt in n_trees_list:\n",
    "    fn_hard = lambda nt=nt: RandomForestRegressor(\n",
    "        n_estimators=nt, max_depth=8, min_samples_leaf=10, random_state=42\n",
    "    )\n",
    "    # train RF on hard labels as regression too (simpler, works fine for QWK)\n",
    "    qwk_h, leaves_h = evaluate_model(fn_hard, X, y_true.astype(float), y_true, folds)\n",
    "    rf_hard.append({\"n_trees\": nt, \"qwk\": qwk_h, \"leaves\": leaves_h})\n",
    "\n",
    "    fn_soft = lambda nt=nt: RandomForestRegressor(\n",
    "        n_estimators=nt, max_depth=8, min_samples_leaf=10, random_state=42\n",
    "    )\n",
    "    qwk_s, leaves_s = evaluate_model(fn_soft, X, soft_targets, y_true, folds)\n",
    "    rf_soft.append({\"n_trees\": nt, \"qwk\": qwk_s, \"leaves\": leaves_s})\n",
    "\n",
    "    print(f\"RF n={nt:>3d}  hard={qwk_h:.4f} ({leaves_h:.0f} leaves)  soft={qwk_s:.4f} ({leaves_s:.0f} leaves)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ba7b3",
   "metadata": {},
   "source": [
    "# GBM — n_estimators sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7aecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_hard = []\n",
    "gbm_soft = []\n",
    "\n",
    "for nt in n_trees_list:\n",
    "    fn_hard = lambda nt=nt: GradientBoostingRegressor(\n",
    "        n_estimators=nt, max_depth=4, learning_rate=0.1, subsample=0.8, random_state=42\n",
    "    )\n",
    "    qwk_h, leaves_h = evaluate_model(fn_hard, X, y_true.astype(float), y_true, folds)\n",
    "    gbm_hard.append({\"n_trees\": nt, \"qwk\": qwk_h, \"leaves\": leaves_h})\n",
    "\n",
    "    fn_soft = lambda nt=nt: GradientBoostingRegressor(\n",
    "        n_estimators=nt, max_depth=4, learning_rate=0.1, subsample=0.8, random_state=42\n",
    "    )\n",
    "    qwk_s, leaves_s = evaluate_model(fn_soft, X, soft_targets, y_true, folds)\n",
    "    gbm_soft.append({\"n_trees\": nt, \"qwk\": qwk_s, \"leaves\": leaves_s})\n",
    "\n",
    "    print(f\"GBM n={nt:>3d}  hard={qwk_h:.4f} ({leaves_h:.0f} leaves)  soft={qwk_s:.4f} ({leaves_s:.0f} leaves)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9940c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "def plot_series(data, label, color, marker, linestyle=\"-\"):\n",
    "    leaves = [d[\"leaves\"] for d in data]\n",
    "    qwks = [d[\"qwk\"] for d in data]\n",
    "    ax.plot(leaves, qwks, marker=marker, color=color, linestyle=linestyle, label=label, markersize=6)\n",
    "\n",
    "# hard label curves (dashed)\n",
    "plot_series(dt_hard, \"Decision Tree (hard)\", \"tab:blue\", \"o\", \"--\")\n",
    "plot_series(rf_hard, \"Random Forest (hard)\", \"tab:orange\", \"s\", \"--\")\n",
    "plot_series(gbm_hard, \"GBM (hard)\", \"tab:green\", \"^\", \"--\")\n",
    "\n",
    "# soft target curves (solid)\n",
    "plot_series(dt_soft, \"Decision Tree (soft)\", \"tab:blue\", \"o\", \"-\")\n",
    "plot_series(rf_soft, \"Random Forest (soft)\", \"tab:orange\", \"s\", \"-\")\n",
    "plot_series(gbm_soft, \"GBM (soft)\", \"tab:green\", \"^\", \"-\")\n",
    "\n",
    "# teacher ceiling\n",
    "ax.axhline(y=0.80, color=\"red\", linestyle=\":\", linewidth=1.5, label=\"Teacher NN (~0.80)\")\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"Total Leaves (avg across folds, log scale)\")\n",
    "ax.set_ylabel(\"QWK\")\n",
    "ax.set_title(\"Interpretability–Performance Tradeoff\")\n",
    "ax.legend(loc=\"lower right\", fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
